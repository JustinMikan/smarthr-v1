"""
SmartHR RAG System - Phase 2: Retrieval & Generation
Streamlit æ‡‰ç”¨ç¨‹å¼ï¼Œæä¾›ä¼æ¥­è¦ç« å•ç­”ä»‹é¢ã€‚
"""
__import__('pysqlite3')
import sys
sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')

import streamlit as st
import time
from langchain_anthropic import ChatAnthropic
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import SentenceTransformerEmbeddings
from langchain.chains import RetrievalQA


@st.cache_resource
def init_embeddings():
    """åˆå§‹åŒ– Embedding æ¨¡å‹"""
    return SentenceTransformerEmbeddings(model_name="all-MiniLM-L6-v2")


@st.cache_resource
def init_vectorstore(_embeddings):
    """åˆå§‹åŒ–å‘é‡è³‡æ–™åº«"""
    return Chroma(
        persist_directory="./chroma_db",
        embedding_function=_embeddings
    )


@st.cache_resource
def init_llm():
    """åˆå§‹åŒ– Claude LLM"""
    return ChatAnthropic(
        model="claude-3-haiku-20240307",
        temperature=0
    )


def create_qa_chain(llm, vectorstore):
    """å»ºç«‹ RetrievalQA éˆ"""
    retriever = vectorstore.as_retriever(search_kwargs={"k": 2})

    qa_chain = RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",
        retriever=retriever,
        return_source_documents=True
    )

    return qa_chain


def stream_text(text, delay=0.02):
    """å°‡æ–‡å­—è½‰æ›ç‚ºç”Ÿæˆå™¨ï¼Œç”¨æ–¼æ‰“å­—æ©Ÿæ•ˆæœ"""
    words = text.split()
    for i, word in enumerate(words):
        if i == 0:
            yield word
        else:
            yield " " + word
        time.sleep(delay)


def main():
    """ä¸»ç¨‹å¼ï¼šStreamlit æ‡‰ç”¨ä»‹é¢"""
    st.set_page_config(page_title="SmartHR ä¼æ¥­è¦ç« åŠ©æ‰‹", page_icon="ğŸ¤–", layout="wide")
    
    # å…¨åŸŸ Custom CSS - ä¿®æ­£ Streamlit é è¨­æ¨£å¼å•é¡Œ
    st.markdown("""
    <style>
        /* ç§»é™¤ Streamlit é è¨­çš„é ‚éƒ¨ padding */
        .main > div {
            padding-top: 2rem;
        }
        
        /* ç§»é™¤é è¨­çš„ block-container padding */
        .block-container {
            padding-top: 1rem;
            padding-bottom: 1rem;
            padding-left: 2rem;
            padding-right: 2rem;
        }
        
        /* èª¿æ•´æ–‡å­—æ®µè½é–“è· */
        p {
            margin-top: 0.5rem;
            margin-bottom: 0.5rem;
            line-height: 1.6;
        }
        
        /* èª¿æ•´æ¨™é¡Œé–“è· */
        h1 {
            margin-top: 0.5rem;
            margin-bottom: 0.75rem;
        }
        
        h2 {
            margin-top: 0.5rem;
            margin-bottom: 0.5rem;
        }
        
        h3 {
            margin-top: 0.5rem;
            margin-bottom: 0.5rem;
        }
        
        /* èª¿æ•´å®¹å™¨é–“è· */
        .stContainer {
            padding-top: 0.5rem;
            padding-bottom: 0.5rem;
        }
        
        /* èª¿æ•´å°è©±è¨Šæ¯é–“è· */
        .stChatMessage {
            padding-top: 0.75rem;
            padding-bottom: 0.75rem;
        }
        
        /* èª¿æ•´æŒ‰éˆ•é–“è· */
        .stButton > button {
            margin-top: 0.25rem;
            margin-bottom: 0.25rem;
        }
        
        /* èª¿æ•´å´é‚Šæ¬„é–“è· */
        .css-1d391kg {
            padding-top: 1rem;
        }
        
        /* é˜²æ­¢æ–‡å­—è·‘ç‰ˆ */
        .stMarkdown {
            word-wrap: break-word;
            overflow-wrap: break-word;
        }
        
        /* èª¿æ•´ expander é–“è· */
        .streamlit-expanderHeader {
            margin-top: 0.5rem;
            margin-bottom: 0.5rem;
        }
        
        /* ç§»é™¤å¤šé¤˜çš„å‚ç›´é–“è· */
        div[data-testid="stVerticalBlock"] > div {
            gap: 0.5rem;
        }
    </style>
    """, unsafe_allow_html=True)
    
    # åˆå§‹åŒ–å°è©±æ­·å²å’Œå¿«é€ŸæŸ¥è©¢ç‹€æ…‹
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "quick_query" not in st.session_state:
        st.session_state.quick_query = None
    
    # å´é‚Šæ¬„
    with st.sidebar:
        st.markdown("## ğŸ¤– SmartHR")
        st.divider()
        
        # å°è©±æ­·å²æ¨™é¡Œ
        st.markdown("### ğŸ’¬ å°è©±æ­·å²")
        
        # é¡¯ç¤ºç°¡çŸ­çš„å°è©±æ­·å²ï¼ˆåƒ…é¡¯ç¤ºæœ€è¿‘çš„å¹¾æ¢ï¼‰
        if st.session_state.messages:
            recent_messages = st.session_state.messages[-5:]  # åªé¡¯ç¤ºæœ€è¿‘5æ¢
            for msg in recent_messages:
                role_icon = "ğŸ‘¤" if msg["role"] == "user" else "ğŸ¤–"
                role_text = "æ‚¨" if msg["role"] == "user" else "åŠ©ç†"
                content_preview = msg["content"][:50] + "..." if len(msg["content"]) > 50 else msg["content"]
                st.markdown(f"{role_icon} **{role_text}**: {content_preview}")
                st.markdown("---")
        else:
            st.markdown("*å°šç„¡å°è©±è¨˜éŒ„*")
        
        st.divider()
        
        if st.button("ğŸ—‘ï¸ æ¸…é™¤å°è©±", type="secondary", use_container_width=True):
            st.session_state.messages = []
            st.session_state.quick_query = None
            st.rerun()
    
    # åˆå§‹åŒ–å…ƒä»¶
    try:
        embeddings = init_embeddings()
        vectorstore = init_vectorstore(embeddings)
        llm = init_llm()
        qa_chain = create_qa_chain(llm, vectorstore)
        system_ready = True
    except Exception as e:
        st.error(f"ç³»çµ±åˆå§‹åŒ–å¤±æ•—ï¼š{str(e)}")
        st.info("è«‹ç¢ºèªå·²åŸ·è¡Œ ingest.py å»ºç«‹å‘é‡è³‡æ–™åº«ï¼Œä¸¦è¨­å®š ANTHROPIC_API_KEY ç’°å¢ƒè®Šæ•¸ã€‚")
        system_ready = False
    
    # ä¸»å…§å®¹å€åŸŸ
    main_container = st.container()
    
    with main_container:
        # Hero Section - åƒ…åœ¨æ²’æœ‰å°è©±æ™‚é¡¯ç¤º
        if not st.session_state.messages:
            hero_container = st.container()
            with hero_container:
                # ç½®ä¸­ä½ˆå±€
                col1, col2, col3 = st.columns([1, 2, 1])
                
                with col2:
                    # ç‹€æ…‹å¾½ç« 
                    st.markdown("""
                    <div style="text-align: center; margin-bottom: 1rem;">
                        <span style="display: inline-flex; align-items: center; gap: 0.5rem; 
                                     padding: 0.5rem 1rem; background-color: #E3F2FD; 
                                     color: #1976D2; border-radius: 999px; font-size: 0.875rem; 
                                     font-weight: 500;">
                            <span style="display: inline-block; width: 8px; height: 8px; 
                                         background-color: #1976D2; border-radius: 50%; 
                                         animation: pulse 2s infinite;"></span>
                            AI åŠ©ç†å·²å°±ç·’
                        </span>
                    </div>
                    <style>
                        @keyframes pulse {
                            0%, 100% { opacity: 1; }
                            50% { opacity: 0.5; }
                        }
                    </style>
                    """, unsafe_allow_html=True)
                    
                    # ä¸»æ¨™é¡Œ
                    st.markdown("""
                    <h1 style="text-align: center; font-size: 3rem; font-weight: bold; 
                               margin-bottom: 1rem; line-height: 1.2;">
                        Hello, Alex!<br>
                        <span style="color: #1976D2;">æœ‰ä»€éº¼æˆ‘å¯ä»¥å¹«ä½ çš„å—ï¼Ÿ</span>
                    </h1>
                    """, unsafe_allow_html=True)
                    
                    # å‰¯æ¨™é¡Œ
                    st.markdown("""
                    <p style="text-align: center; font-size: 1.125rem; color: #666; 
                              margin-bottom: 2rem; max-width: 600px; margin-left: auto; 
                              margin-right: auto;">
                        æˆ‘æ˜¯æ‚¨çš„æ™ºæ…§äººè³‡åŠ©ç†ï¼Œå¯ä»¥å›ç­”ä»»ä½•é—œæ–¼å…¬å¸è¦ç« åˆ¶åº¦çš„å•é¡Œ
                    </p>
                    """, unsafe_allow_html=True)
                    
                    st.markdown("<br>", unsafe_allow_html=True)
        
        # å°è©±å€åŸŸ
        chat_container = st.container()
        with chat_container:
            # å¦‚æœæœ‰å°è©±æ­·å²ï¼Œé¡¯ç¤ºå°è©±
            if st.session_state.messages:
                st.markdown("### ğŸ’¬ å°è©±")
                for message in st.session_state.messages:
                    with st.chat_message(message["role"]):
                        st.write(message["content"])
                        # å¦‚æœæœ‰åƒè€ƒä¾†æºï¼Œé¡¯ç¤ºåœ¨ expander ä¸­
                        if message["role"] == "assistant" and "sources" in message:
                            with st.expander("ğŸ“š æŸ¥çœ‹åƒè€ƒä¾†æº"):
                                for i, doc in enumerate(message["sources"], 1):
                                    st.markdown(f"**ä¾†æº {i}:**")
                                    st.text(doc.page_content[:300] + "..." if len(doc.page_content) > 300 else doc.page_content)
                                    st.divider()
        
        # è™•ç†å¿«é€ŸæŸ¥è©¢ï¼ˆåœ¨æœå°‹è¼¸å…¥ä¹‹å‰ï¼‰
        if st.session_state.quick_query and system_ready:
            prompt = st.session_state.quick_query
            st.session_state.quick_query = None
            
            # é¡¯ç¤ºä½¿ç”¨è€…è¨Šæ¯
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.write(prompt)

            # ç”Ÿæˆ AI å›ç­”
            with st.chat_message("assistant"):
                with st.spinner("æ­£åœ¨æŸ¥è©¢ä¸­..."):
                    try:
                        result = qa_chain.invoke({"query": prompt})
                        answer = result["result"]
                        sources = result.get("source_documents", [])

                        # ä½¿ç”¨æ‰“å­—æ©Ÿæ•ˆæœé¡¯ç¤ºå›ç­”
                        response_placeholder = st.empty()
                        full_response = ""
                        for chunk in stream_text(answer):
                            full_response += chunk
                            response_placeholder.write(full_response + "â–Œ")
                        
                        # ç§»é™¤æ¸¸æ¨™ä¸¦é¡¯ç¤ºå®Œæ•´å›ç­”
                        response_placeholder.write(full_response)

                        # é¡¯ç¤ºåƒè€ƒä¾†æº
                        if sources:
                            with st.expander("ğŸ“š æŸ¥çœ‹åƒè€ƒä¾†æº"):
                                for i, doc in enumerate(sources, 1):
                                    st.markdown(f"**ä¾†æº {i}:**")
                                    st.text(doc.page_content[:300] + "..." if len(doc.page_content) > 300 else doc.page_content)
                                    st.divider()

                        # ä¿å­˜åˆ°å°è©±æ­·å²
                        st.session_state.messages.append({
                            "role": "assistant",
                            "content": full_response,
                            "sources": sources
                        })
                        st.rerun()

                    except Exception as e:
                        error_msg = f"æŸ¥è©¢å¤±æ•—ï¼š{str(e)}"
                        st.error(error_msg)
                        st.info("è«‹ç¢ºèª ANTHROPIC_API_KEY ç’°å¢ƒè®Šæ•¸å·²æ­£ç¢ºè¨­å®šã€‚")
                        st.session_state.messages.append({
                            "role": "assistant",
                            "content": error_msg
                        })
        
        # æœå°‹æ¬„ä½å€åŸŸ
        search_container = st.container()
        with search_container:
            if not st.session_state.messages:
                st.markdown("<br>", unsafe_allow_html=True)
            
            # æœå°‹è¼¸å…¥æ¡†
            if prompt := st.chat_input("è«‹è¼¸å…¥æ‚¨çš„å•é¡Œï¼Œä¾‹å¦‚ï¼šè«‹å‡éœ€è¦ä»€éº¼è­‰æ˜ï¼Ÿ"):
                # é¡¯ç¤ºä½¿ç”¨è€…è¨Šæ¯
                st.session_state.messages.append({"role": "user", "content": prompt})
                with st.chat_message("user"):
                    st.write(prompt)

                # ç”Ÿæˆ AI å›ç­”
                if system_ready:
                    with st.chat_message("assistant"):
                        with st.spinner("æ­£åœ¨æŸ¥è©¢ä¸­..."):
                            try:
                                result = qa_chain.invoke({"query": prompt})
                                answer = result["result"]
                                sources = result.get("source_documents", [])

                                # ä½¿ç”¨æ‰“å­—æ©Ÿæ•ˆæœé¡¯ç¤ºå›ç­”
                                response_placeholder = st.empty()
                                full_response = ""
                                for chunk in stream_text(answer):
                                    full_response += chunk
                                    response_placeholder.write(full_response + "â–Œ")
                                
                                # ç§»é™¤æ¸¸æ¨™ä¸¦é¡¯ç¤ºå®Œæ•´å›ç­”
                                response_placeholder.write(full_response)

                                # é¡¯ç¤ºåƒè€ƒä¾†æº
                                if sources:
                                    with st.expander("ğŸ“š æŸ¥çœ‹åƒè€ƒä¾†æº"):
                                        for i, doc in enumerate(sources, 1):
                                            st.markdown(f"**ä¾†æº {i}:**")
                                            st.text(doc.page_content[:300] + "..." if len(doc.page_content) > 300 else doc.page_content)
                                            st.divider()

                                # ä¿å­˜åˆ°å°è©±æ­·å²
                                st.session_state.messages.append({
                                    "role": "assistant",
                                    "content": full_response,
                                    "sources": sources
                                })
                                st.rerun()

                            except Exception as e:
                                error_msg = f"æŸ¥è©¢å¤±æ•—ï¼š{str(e)}"
                                st.error(error_msg)
                                st.info("è«‹ç¢ºèª ANTHROPIC_API_KEY ç’°å¢ƒè®Šæ•¸å·²æ­£ç¢ºè¨­å®šã€‚")
                                st.session_state.messages.append({
                                    "role": "assistant",
                                    "content": error_msg
                                })
        
        # å¿«é€Ÿå­˜å–å€åŸŸ - åƒ…åœ¨æ²’æœ‰å°è©±æ™‚é¡¯ç¤º
        if not st.session_state.messages:
            st.markdown("<br><br>", unsafe_allow_html=True)
            quick_access_container = st.container()
            with quick_access_container:
                st.markdown("""
                <div style="text-align: center; margin-bottom: 1.5rem;">
                    <h2 style="font-size: 0.875rem; font-weight: 600; color: #666; 
                               text-transform: uppercase; letter-spacing: 0.05em;">
                        å¿«é€Ÿå­˜å– Quick Access
                    </h2>
                </div>
                """, unsafe_allow_html=True)
                
                # å¿«é€ŸæŸ¥è©¢å¡ç‰‡
                col1, col2, col3, col4 = st.columns(4)
                
                quick_queries = [
                    ("ğŸ“… è«‹å‡è¦å®š", "è«‹å‡éœ€è¦ä»€éº¼è­‰æ˜ï¼Ÿè«‹å‡çš„æµç¨‹æ˜¯ä»€éº¼ï¼Ÿ"),
                    ("ğŸ’° å ±å¸³æµç¨‹", "å ±å¸³éœ€è¦å“ªäº›æ–‡ä»¶ï¼Ÿå ±å¸³çš„æµç¨‹æ˜¯ä»€éº¼ï¼Ÿ"),
                    ("ğŸ å“¡å·¥ç¦åˆ©", "å…¬å¸æä¾›å“ªäº›å“¡å·¥ç¦åˆ©ï¼Ÿ"),
                    ("ğŸ“‹ è¦ç« åˆ¶åº¦", "å…¬å¸çš„è¦ç« åˆ¶åº¦æœ‰å“ªäº›ï¼Ÿ")
                ]
                
                for i, (icon_title, query) in enumerate(quick_queries):
                    with [col1, col2, col3, col4][i]:
                        if st.button(
                            icon_title,
                            key=f"quick_{i}",
                            use_container_width=True,
                            type="secondary"
                        ):
                            st.session_state.quick_query = query
                            st.rerun()
        
        # Footer
        st.markdown("<br><br>", unsafe_allow_html=True)
        footer_container = st.container()
        with footer_container:
            st.markdown("""
            <div style="text-align: center; padding: 1rem; border-top: 1px solid #e0e0e0; 
                       margin-top: 2rem;">
                <p style="font-size: 0.875rem; color: #666;">
                    Â© 2026 SmartHR. ç”± AI é©…å‹•çš„ä¼æ¥­äººè³‡ç³»çµ±ã€‚
                </p>
            </div>
            """, unsafe_allow_html=True)


if __name__ == "__main__":
    main()
